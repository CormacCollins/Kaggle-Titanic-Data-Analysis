{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/27934885/how-to-hide-code-from-cells-in-ipython-notebook-visualized-with-nbviewer\n",
    "#cool code for a button to hide code \n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tabulate\n",
    "import statistical_tools as s_tools\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.formula.api import glm \n",
    "#plotting with seaborn\n",
    "#https://cmdlinetips.com/2019/02/how-to-make-histogram-in-python-with-pandas-and-seaborn/\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Modelilng survival rate\n",
    "\n",
    "We have done a big amount of exploration and significance testing with some of our data set, so now it's time to start doing some modelling and see if we can predict survival rate from some of the variables we suspect are correlated. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to model off the main influencers that we found, that is: Pclass, Sex, Age and Parch.\n",
    "\n",
    "\n",
    "We noticed some potential interactions before between Parch and PClass, or PClass and sex. So we will do a more numerical test on our model including the above vaiables. We will use the variance inflation factor(VIF), which gives us a measure of coliniearity between dependent variables. However this again is just a guide not a definite, I have read that VIF interpretation is not well understood with categorical variables. Regardless, we will apply the recommended 2.5 lv cut off for recognizing any major interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null values with random samples from distr\n",
    "mean = np.mean(train['Age'])\n",
    "std = np.std(train['Age'])\n",
    "\n",
    "rand_age = np.random.randint(mean - std, mean + std, size = train['Age'].isnull().sum())\n",
    "age_slice = train[\"Age\"].copy()\n",
    "age_slice[np.isnan(age_slice)] = rand_age\n",
    "train[\"Age\"] = age_slice\n",
    "train[\"Age\"] = train[\"Age\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   variables        VIF\n",
      "0        Age   1.191623\n",
      "1      Parch   1.276765\n",
      "2      SibSp   1.253895\n",
      "3    class 2   1.524585\n",
      "4    class 3   1.677099\n",
      "5          F   1.096671\n",
      "6  Intercept  15.226201\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "\n",
    "# Get variables for which to compute VIF and add intercept term \n",
    "#Pclass == 1 and Sex == male are the reference factors for those categories - it is redundant to put them in and actually causes errors\n",
    "\n",
    "X = train[['Age', 'Parch', 'SibSp']].copy()\n",
    "X['class 2'] = np.where(train['Pclass']== 2, 1, 0)\n",
    "X['class 3'] = np.where(train['Pclass']== 3, 1, 0)\n",
    "X['F'] = np.where(train['Sex']== 'female', 1, 0)\n",
    "X['Intercept'] = 1 \n",
    "\n",
    "  \n",
    "\n",
    "# Compute and view VIF \n",
    "vif = pd.DataFrame() \n",
    "vif[\"variables\"] = X.columns \n",
    "\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])] \n",
    "\n",
    "  \n",
    "\n",
    "# View results using print \n",
    "\n",
    "print(vif) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see tht there are no values above 2.5 so for now we will choose to keep them in. Note: 'Pclass == 1' and 'Sex == male' are the reference factors for those categories - therefore it is redundant to put them in this test, as the test is comparing the other factors against the reference factors (It also causes errors in the function if you don't remove these).\n",
    "\n",
    "*Also another note, we saw some strong influence by Parch but only in the lower numbers 0-2, so a future model might add that as a categorical model instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  450\n",
      "Model:                            GLM   Df Residuals:                      443\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -204.51\n",
      "Date:                Thu, 14 May 2020   Deviance:                       409.02\n",
      "Time:                        16:24:58   Pearson chi2:                     460.\n",
      "No. Iterations:                     5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================================\n",
      "                                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Intercept                               0.7830      0.483      1.620      0.105      -0.165       1.731\n",
      "C(Sex, Treatment('male'))[T.female]     2.8186      0.265     10.644      0.000       2.300       3.338\n",
      "C(Pclass, Treatment(1))[T.2]           -0.8823      0.372     -2.372      0.018      -1.611      -0.153\n",
      "C(Pclass, Treatment(1))[T.3]           -1.7445      0.333     -5.245      0.000      -2.396      -1.093\n",
      "Age                                    -0.0367      0.011     -3.382      0.001      -0.058      -0.015\n",
      "Parch                                   0.0288      0.173      0.166      0.868      -0.310       0.368\n",
      "SibSp                                  -0.3992      0.151     -2.640      0.008      -0.696      -0.103\n",
      "=======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define model formula \n",
    "\n",
    "train_half = train[0:450].copy()\n",
    "train_2nd_half = train[450:len(train)].copy()\n",
    "\n",
    "formula = 'Survived ~ C(Sex, Treatment(\\'male\\')) + C(Pclass, Treatment(1)) + Age + Parch + SibSp' \n",
    "\n",
    "model = glm(formula, data = train_half, family = sm.families.Binomial()).fit() \n",
    "\n",
    "print(model.summary()) \n",
    "pred_glm = model.predict(train_2nd_half) \n",
    "#predicted_survive = (pred_glm >= 0.5)\n",
    "train_2nd_half['expected_survive'] = pred_glm\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading our coefficients in our output, we see mainly what we expected. Things such as; \n",
    "<ul>\n",
    "    <li> being female has a strong positive effect</li>\n",
    "    <li> dropping down class has a negative effect </li>\n",
    "    <li> increases in age slightly lower our survival (maybe a future category is to just check if young or not)</li>\n",
    "    <li> Parch strangely has a positive effect as it increases (this is likely from the strength of being ~ Parch = 4, next time having only the categories of Parch 0,1 or 2 would be better</li>\n",
    "    <li> SibSp also wasn't overly robust in some of the numbers, we could remove a few of the counts in a similar way to Parch</li>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "Nevertheless, this model looks like a nice start, in addition I should note, we have used about 65% (Arbitrarily chosen) of the train data on our model, so we can then use the remaining portion to test our classification threshold. This model is logistic GLM, therefore it will be classifying each passenger on a probability from 0-1, so we need to decide what level cut off is the probbility we expect someone to survive.\n",
    "\n",
    "We will do this by running our calculated model at varying levels of probability thresholds, and comparing how many the model predicts correctly for each threshold value. We will pick our most optimal number from our best prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>proportion correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  proportion correct\n",
       "20   0.512821                 349\n",
       "21   0.538462                 349\n",
       "22   0.564103                 351\n",
       "23   0.589744                 352\n",
       "24   0.615385                 352\n",
       "25   0.641026                 358"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute estimated probabilities for GLM model: pred_glm\n",
    "\n",
    "n = 40 \n",
    "thresholds = list()\n",
    "prop_corr = list()\n",
    "\n",
    "\n",
    "for i in np.linspace(0.0, 1, n):\n",
    "    predicted_survive = (pred_glm >= i)\n",
    "    num_correct = (predicted_survive.astype(bool)) == (train_2nd_half['Survived'].astype(bool))\n",
    "    s = pd.DataFrame({'pred': predicted_survive,\n",
    "                  'surv': train_2nd_half['Survived'],\n",
    "                     'AND': num_correct})\n",
    "    #print(s[0:20])\n",
    "    #break\n",
    "    #l.append([i, sum(num_correct)])\n",
    "    thresholds.append(i)\n",
    "    prop_corr.append(sum(num_correct))\n",
    "\n",
    "df = pd.DataFrame({'threshold': thresholds, 'proportion correct':prop_corr})\n",
    "m = df['proportion correct'].idxmax()\n",
    "pr = df['threshold'].iloc[m]   \n",
    "\n",
    "df.iloc[20:26]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.6923076923076923\n",
      "Predictions correct: 360/441 == 0.8163265306122449\n"
     ]
    }
   ],
   "source": [
    "print('Best threshold: {}'.format(pr))\n",
    "print('Predictions correct: {}/{} == {}'.format(df['proportion correct'].max(), len(train_2nd_half), df['proportion correct'].max()/ len(train_2nd_half)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can extract our most optimal threshold and then use it in our model when we classify our test data. We will then submit this data to Kaggle and see how good the predictions were!\n",
    "We will also train it again but this time with the full data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  891\n",
      "Model:                            GLM   Df Residuals:                      884\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -396.13\n",
      "Date:                Thu, 14 May 2020   Deviance:                       792.25\n",
      "Time:                        16:25:20   Pearson chi2:                     917.\n",
      "No. Iterations:                     5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================================\n",
      "                                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Intercept                               1.1974      0.341      3.516      0.000       0.530       1.865\n",
      "C(Sex, Treatment('male'))[T.female]     2.7733      0.199     13.938      0.000       2.383       3.163\n",
      "C(Pclass, Treatment(1))[T.2]           -1.1664      0.261     -4.468      0.000      -1.678      -0.655\n",
      "C(Pclass, Treatment(1))[T.3]           -2.3119      0.241     -9.591      0.000      -2.784      -1.839\n",
      "Age                                    -0.0371      0.007     -4.981      0.000      -0.052      -0.023\n",
      "Parch                                  -0.0805      0.114     -0.705      0.481      -0.304       0.143\n",
      "SibSp                                  -0.3379      0.109     -3.112      0.002      -0.551      -0.125\n",
      "=======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create model on full data then run on test data\n",
    "model = glm(formula, data = train, family = sm.families.Binomial()).fit() \n",
    "print(model.summary()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_glm = model.predict(test) \n",
    "predicted_survive = (pred_glm >= pr)\n",
    "test['Survived'] = predicted_survive.astype(int)\n",
    "test_file = test[['PassengerId', 'Survived']]\n",
    "test_file.to_csv('submission.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'0.784' accuracy score on kaggle - not bad!\n",
    "\n",
    "In our next attempt we might tweak some of the factors a bit to see if we can optimize it, also using Cabin should be another thing we might quickly explore next time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
